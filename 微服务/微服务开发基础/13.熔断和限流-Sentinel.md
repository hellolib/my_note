# 一. 服务雪崩

- 分布式系统中经常会出现某个基础服务不可用造成整个系统不可用的情况, 这种现象被称为服务雪崩效应. 为了应对服务雪崩, 一种常见的做法是手动服务降级.

## 1. 定义

- 服务雪崩效应是一种因 **服务提供者** 的不可用导致 **服务调用者** 的不可用,并将不可用 **逐渐放大** 的过程.如果所示:

  <img src="https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/bVziad-20211119180400382.png" alt="图片描述" style="zoom:50%;" />

1. A为服务提供者, B为A的服务调用者, C和D是B的服务调用者. 

   >**服务不可用** 的原因有:
   >
   >- 硬件故障
   >- 程序Bug
   >- 缓存击穿
   >- 用户大量请求

2. 当A的不可用时,B调用A 导致B的并发挤压,最终 引起B的不可用,并将不可用逐渐放大C和D时, 服务雪崩就形成了.

   >当服务调用者使用 **同步调用** 时, 会产生大量的等待线程占用系统资源. 一旦线程资源被耗尽,服务调用者提供的服务也将处于不可用状态

## 2. 服务雪崩的应对策略

>1. 流量控制 : 稍后重试
>2. 改进缓存模式
>3. 服务自动扩容
>
>4. 服务调用者降级服务 : 访问人数过多,  请稍后重试
>5. 熔断限流

- 不可用服务的调用快速失败一般通过 **超时机制**, **熔断器** 和熔断后的 **降级方法** 来实现.

针对造成服务雪崩的不同原因, 可以使用不同的应对策略:

1. 流量控制
2. 改进缓存模式
3. 服务自动扩容
4. 服务调用者降级服务

**流量控制** 的具体措施包括:

- 网关限流
- 用户交互限流
- 关闭重试

因为Nginx的高性能, 目前一线互联网公司大量采用Nginx+Lua的网关进行流量控制, 由此而来的OpenResty也越来越热门. 

用户交互限流的具体措施有: 1. 采用加载动画,提高用户的忍耐等待时间. 2. 提交按钮添加强制等待时间机制.

**改进缓存模式** 的措施包括:

- 缓存预加载
- 同步改为异步刷新

**服务自动扩容** 的措施主要有:

- AWS的auto scaling

**服务调用者降级服务** 的措施包括:

- 资源隔离
- 对依赖服务进行分类
- 不可用服务的调用快速失败

资源隔离主要是对调用服务的线程池进行隔离. 

我们根据具体业务,将依赖服务分为: 强依赖和若依赖. 强依赖服务不可用会导致当前业务中止,而弱依赖服务的不可用不会导致当前业务的中止. 

## 3. 熔断和降级

### 3.1 熔断

> 比如A服务访问B服务,这个时候B服务很慢-B服务压力过大, 导致了出现了不少请求错误,调用方很容易出现一个问题: 每次调用都超时2k, 结果这个时侯数据库出现了问题,超时重试-网络2k的流量突然变成了3k 这让原本就满负荷的b服务雪上加霜,如果这个时候调用方有一种机制:比如说1.发现了大部分请求很慢-50% 请求都很慢,2.发现我的请求有50%都错误了3.粗我数量很多,比如1s出现了20个错误 , 就**在短时间内对新来的请求不再处理,**防止雪崩

- 熔断的三种状态

  1. **关闭状态**: 服务正常，维护失败率统计，达到失败率阈值 时，转到开启状态。
  2. **开启状态**: 服务异常，调用 fallback函数，一段时间后，进 入半开启状态。
  3. **半开启状态**:尝试恢复服务，失败率高于阈值，进入开启状 态，低于阈值，进入关闭状态。

  <img src="https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20211209145055549.png" alt="image-20211209145055549" style="zoom:40%;" />

### 3.2 降级

>当服务器压力剧增时，根据业务策略降级(引导至2级页面)，以此释放服务资源保证业务正常。

## 4. 限流

### 4.1 漏桶限流

- 水（请求）先进入到漏桶里，漏桶以一定的速度出水，当水流入速度过大会直接溢出(**过多的请求直接抛弃**或者降级)，可以看出漏桶算法能强行限制数据的传输速率。

<img src="https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20211209164424350.png" alt="image-20211209164424350" style="zoom: 50%;" />

- 对于很多应用场景来说，除了要求能够限制数据的平均传输速率外，还要求允许某种程度的突发传输。这时候漏桶算法可能就不合适了，令牌桶算法更为适合。如图2所示，令牌桶算法的原理是系统会以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。

### 4.2 令牌桶限流

> 类库 time/rate  (rate:速率)

- 令牌桶算法的原理是系统会以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务或降级。

  <img src="https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20211209164645108.png" alt="image-20211209164645108" style="zoom: 39%;" />

# 二. time/rate (令牌桶) 限流

>time/rate 官方库是基于令牌桶算法实现限流

- 基本参数

  - limiter := rate.NewLimiter(limit, burst)  limit表示每秒产生token数, burst是最多存token数

  - limiter.SetLimit(limit) 动态设置limit

  - limiter.SetBurst(burst)  动态设置burst

  - **Allow** 判断当前是否可以取到token 

  - **Wait**  阻塞直到取到token 

  - **Reserve** 返回等待时间(预估), 再去取token 

    `allow, wait reserve 每次调用都是一次请求, 需要根据不同的场景使用三个方法`

## 1. 简单实现

```go
/*
 * @date: 2021/12/9
 * @desc: ...
 */

package main

import (
	"context"
	"golang.org/x/time/rate"
	"log"
	"testing"
	"time"
)

func TestRateLimiter(t *testing.T) {
	l := rate.NewLimiter(1, 5)
	log.Println(l.Limit(), l.Burst())
	for i := 0; i < 100; i++ {
		//阻塞等待直到，取到一个token
		log.Println("before Wait")
		c, _ := context.WithTimeout(context.Background(), time.Second*2)
		if err := l.Wait(c); err != nil {
			log.Println("limiter wait err:" + err.Error())
		}
		log.Println("after Wait")

		// 返回需要等待多久才有新的token,这样就可以等待指定时间执行任务
		r := l.Reserve()
		log.Println("reserve Delay:", r.Delay())

		//判断当前是否可以取到token
		a := l.Allow()
		log.Println("Allow:", a)
	}
}

/*
2021/12/09 16:59:59 1 5
2021/12/09 16:59:59 before Wait     // 第一次请求
2021/12/09 16:59:59 after Wait     
2021/12/09 16:59:59 reserve Delay: 0s  // 第二次请求
2021/12/09 16:59:59 Allow: true       //3请求
2021/12/09 16:59:59 before Wait       // 4
2021/12/09 16:59:59 after Wait      
2021/12/09 16:59:59 reserve Delay: 0s  // 5
2021/12/09 16:59:59 Allow: false       // 6
2021/12/09 16:59:59 before Wait        //7
... //..
*/
```

## 2. 给代理设置限流

- middleware

  ```go
  package middleware
  
  import (
  	"github.com/e421083458/gateway_demo/proxy/public"
  	"strings"
  )
  
  func JwtMiddleWare() func(c *SliceRouterContext) {
  	return func(c *SliceRouterContext) {
  		token := c.Req.Header.Get("Authorization")
  		token = strings.Replace(token, "Bearer ", "", -1)
  		if _, err := public.Decode(token); err != nil {
  			c.Rw.Write([]byte("jwt auth invalid:" + err.Error()))
  			c.Abort()
  			return
  		}
  		c.Next()
  	}
  }
  ```

- main.go

  ```go
  /*
   * @date: 2021/12/9
   * @desc: ...
   */
  
  package main
  
  import (
  	"log"
  	"net/http"
  	"net/url"
  	middleware "picturePro/gateWareCompose/middleWare"
  	"picturePro/gateWareCompose/proxy"
  )
  
  var serverAddr = "127.0.0.1:2002"
  
  func main() {
  	coreFunc := func(context *middleware.SliceRouterContext) http.Handler {
  		rs1 := "http://127.0.0.1:2003/base"
  		url1, err1 := url.Parse(rs1)
  		if err1 != nil {
  			log.Println(err1)
  		}
  
  		rs2 := "http://127.0.0.1:2004/base"
  		url2, err2 := url.Parse(rs2)
  		if err2 != nil {
  			log.Println(err2)
  		}
  
  		urls := []*url.URL{url1, url2}
  		return proxy.NewMultipleHostsReverseProxy(context, urls)
  	}
  	log.Println("Starting httpserver at " + serverAddr)
  	sliceRouter := middleware.NewSliceRouter()
  	sliceRouter.Group("/").Use(middleware.RateLimiter())
  	routerHandler := middleware.NewSliceRouterHandler(coreFunc, sliceRouter)
  	err := http.ListenAndServe(serverAddr, routerHandler)
  	if err != nil {
  		panic(err)
  	}
  }
  
  ```

  

# 三. hystrix-go 熔断降级

## 1. 简单实现

```go
/*
 * @date: 2021/12/9
 * @desc: ...
 */

package main

import (
	"errors"
	"github.com/afex/hystrix-go/hystrix"
	"log"
	"net/http"
	"testing"
	"time"
)

func Test_main(t *testing.T) {
	hystrixStreamHandler := hystrix.NewStreamHandler()
	hystrixStreamHandler.Start()
	
	go http.ListenAndServe(":8074", hystrixStreamHandler)// web数据监控页面
	hystrix.ConfigureCommand("aaa", hystrix.CommandConfig{
		Timeout:                1000, // 单次请求 超时时间
		MaxConcurrentRequests:  1,    // 最大并发量
		SleepWindow:            5000, // 熔断后多久去尝试服务是否可用
		RequestVolumeThreshold: 1,    // 验证熔断的 请求数量, 10秒内采样
		ErrorPercentThreshold:  1,    // 验证熔断的 错误百分比
	})
	for i := 0; i < 10000; i++ {
		// 异步调用使用hystrix.Go()
		err := hystrix.Do("aaa", func() error {
			// test case 1 并发测试
			if i == 0 {
				return errors.New("service error")
			}
			// test case 2 超时测试
			//time.Sleep(2 * time.Second)
			log.Println("do servers")
			return nil
		}, func(err error) error {
			log.Println("log----cal back", err.Error())
			return err

		})
		if err != nil {
			log.Println("hystrix err:" + err.Error())
			time.Sleep(1 * time.Second)
			log.Println("sleep 1 second")
		}
	}
	time.Sleep(100 * time.Second)
}

```

## 2. hystrix-dashboard 

1. docker拉取镜像 `docker pull mlabouardy/hystrix-dashboard`

2. 启动`docker run -d -p 8080:9002 --name hystrix-dashboard mlabouardy/hystrix-dashboard:latest`

3. 访问`http://127.0.0.1:8080/hystrix`,并添加:8074端口服务

   ![image-20211209162159583](https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20211209162159583.png)

4. 监控

   ![image-20211209162258018](https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20211209162258018.png)



# 四. Sentinel

> doc : https://sentinelguard.io/zh-cn/docs/golang/basic-api-usage.html

### 1. 流量控制

#### 1.1 QPS 流量控制

- doc: https://sentinelguard.io/zh-cn/docs/golang/flow-control.html

- 使用示例: https://github.com/alibaba/sentinel-golang/tree/master/example/flow/qps
- api文档: https://sentinelguard.io/zh-cn/docs/golang/basic-api-usage.html

```go
package main

import (
	"fmt"
	sentinel "github.com/alibaba/sentinel-golang/api"
	"github.com/alibaba/sentinel-golang/core/base"
	"github.com/alibaba/sentinel-golang/core/config"
	"github.com/alibaba/sentinel-golang/core/flow"
	"github.com/alibaba/sentinel-golang/logging"
	"log"
)

const resName = "example-flow-qps-resource"

func main() {
	// We should initialize Sentinel first.
	conf := config.NewDefaultConfig()
	// for testing, logging output to console
	conf.Sentinel.Log.Logger = logging.NewConsoleLogger()
	err := sentinel.InitWithConfig(conf)

	if err != nil {
		log.Fatalf("初始化失败: %v", err.Error())
	}
	_, err = flow.LoadRules([]*flow.Rule{
		{
			Resource:               resName,
			TokenCalculateStrategy: flow.Direct, // qps
			ControlBehavior:        flow.Reject, // 直接拒接
			Threshold:              10,  // 10 请求
			StatIntervalInMs:       1000, // 1s
		},
	})
	if err != nil {
		log.Fatalf("Unexpected error: %+v", err)
		return
	}

	for i := 0; i < 12; i++ {
		e, b := sentinel.Entry(resName, sentinel.WithTrafficType(base.Inbound))
		if b != nil {
			fmt.Println(i,"限流")
		} else {
			// Passed, wrap the logic here.
			fmt.Println(i,"通过")

			// Be sure the entry is exited finally.
			e.Exit()
		}
	}

}

```

#### 2.2 WarmUp 冷启动预热

- WarmUp方式，即预热/冷启动方式。当系统长期处于低水位的情况下，当流量突然增加时，直接把系统拉升到高水位可能瞬间把系统压垮。通过"冷启动"，让通过的流量缓慢增加，在一定时间内逐渐增加到阈值上限，给冷系统一个预热的时间，避免冷系统被压垮。这块设计和Java类似，可以参考[限流 冷启动](https://github.com/alibaba/Sentinel/wiki/限流---冷启动) 通常冷启动的过程系统允许通过的 QPS 曲线如下图所示： 

  <img src="https://user-images.githubusercontent.com/9434884/68292392-b5b0aa00-00c6-11ea-86e1-ecacff8aab51.png" alt="img" style="zoom:50%;" />

- 示例代码: https://github.com/alibaba/sentinel-golang/blob/master/example/flow/warm_up/qps_warm_up_example.go
- 配置说明: https://sentinelguard.io/zh-cn/docs/golang/flow-control.html

### 2. 熔断降级

- doc: https://sentinelguard.io/zh-cn/docs/golang/circuit-breaking.html

#### 2.1 熔断器模型

- Sentinel 熔断降级基于熔断器模式 (circuit breaker pattern) 实现。熔断器内部维护了一个熔断器的状态机，状态机的转换关系如下图所示：

<img src="https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/82635455-ca075f00-9c32-11ea-9e99-d67518923e0d.png" alt="circuit-breaker" style="zoom: 33%;" />

熔断器有三种状态：

1. Closed 状态：也是初始状态，该状态下，熔断器会保持闭合，对资源的访问直接通过熔断器的检查。
2. Open 状态：断开状态，熔断器处于开启状态，对资源的访问会被切断。
3. Half-Open 状态：半开状态，该状态下除了探测流量，其余对资源的访问也会被切断。探测流量指熔断器处于半开状态时，会周期性的允许一定数目的探测请求通过，如果探测请求能够正常的返回，代表探测成功，此时熔断器会重置状态到 Closed 状态，结束熔断；如果探测失败，则回滚到 Open 状态。

这三种状态之间的转换关系这里做一个更加清晰的解释：

1. 初始状态下，熔断器处于 Closed 状态。如果基于熔断器的统计数据表明当前资源触发了设定的阈值，那么熔断器会切换状态到 Open 状态；
2. Open 状态即代表熔断状态，所有请求都会直接被拒绝。熔断器规则中会配置一个熔断超时重试的时间，经过熔断超时重试时长后熔断器会将状态置为 Half-Open 状态，从而进行探测机制；
3. 处于 Half-Open 状态的熔断器会周期性去做探测, 服务没有问题转换为closed状态

#### 2.2 熔断策略

Sentinel 熔断器的三种熔断策略都支持静默期 (规则中通过MinRequestAmount字段表示)。静默期是指一个最小的静默请求数，在一个统计周期内，如果对资源的请求数小于设置的静默数，那么熔断器将不会基于其统计值去更改熔断器的状态。静默期的设计理由也很简单，举个例子，假设在一个统计周期刚刚开始时候，第 1 个请求碰巧是个慢请求，这个时候这个时候的慢调用比例就会是 100%，很明显是不合理，所以存在一定的巧合性。所以静默期提高了熔断器的精准性以及降低误判可能性。

Sentinel 支持以下几种熔断策略：

- 慢调用比例策略 (SlowRequestRatio)：Sentinel 的熔断器不在静默期，并且慢调用的比例大于设置的阈值，则接下来的熔断周期内对资源的访问会自动地被熔断。该策略下需要设置允许的调用 RT 临界值（即最大的响应时间），对该资源访问的响应时间大于该阈值则统计为慢调用。
- 错误比例策略 (ErrorRatio)：Sentinel 的熔断器不在静默期，并且在统计周期内资源请求访问异常的比例大于设定的阈值，则接下来的熔断周期内对资源的访问会自动地被熔断。
- 错误计数策略 (ErrorCount)：Sentinel 的熔断器不在静默期，并且在统计周期内资源请求访问异常数大于设定的阈值，则接下来的熔断周期内对资源的访问会自动地被熔断。

注意：这里的错误比例熔断和错误计数熔断指的业务返回错误的比例或则计数。也就是说，如果规则指定熔断器策略采用错误比例或则错误计数，那么为了统计错误比例或错误计数，需要调用API： `api.TraceError(entry, err)` 埋点每个请求的业务异常。

> 示例代码:
>
> https://github.com/alibaba/sentinel-golang/tree/master/example/circuitbreaker



