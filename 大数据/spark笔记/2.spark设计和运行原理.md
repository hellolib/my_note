## 1. Spark 特点

1. **Spark 运行速度很快**

- 内存中做计算, 使用循环数据流 (即上一次 Reduce 的结果作为 input 给下一次 MapReduce 使用) 很少使用 IO 流
  - **能够不落磁盘, 尽量不落, 但不是 100% 不落**
- DAG 设计机制 - 流水线优化(上一次 Reduce 的结果作为 input 给下一次 MapReduce 使用) 

2. 应用场景广泛,通用性强
3. 容易使用, 支持java scala python r语言等
4. 运行模式多样, 可以单机也可以集群运行, 本地和云端都支持
5. 支持数据源广泛 hive hbase hdfs...

## 2. Spark 生态

- spark 可以使用 hadoop 的yarn 资源调度

#### 2.1应用场景

- 复杂批处理
- 历史数据的交互式查询
- 流处理(实时)

![image-20210907105017729](https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20210907105017729.png)

```python
# 传统方式 hadoop + impala + storm方式的缺点
1. 资源不好利用, 各个系统不能很好的分配资源
2. 无法无缝共享数据
3. 使用成本较高, 维护成本高
```

#### 2.2 spark 组件架构

![image-20210907104411549](https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20210907104411549.png)

## 3.spark运行架构

#### 3.1 基本概念

![image-20210907105405655](https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20210907105405655.png)

- **RDD**: Resillient DIstributed Dataset. 弹性分布式内存数据集 (高度受限的共享内存模型-只读)
  - **分布式对象, 本质上是一个只读的分区记录集合, 数据特别大的话, 可以分布式的存在不同的机器上, 每一个机器都是数据的一个分区, 所以就可以进行分布式的高效的并行计算**
- **DAG**: RDD 之间的依赖关系(有向无环图)
- **Executor**: 运行在工作节点 (Worker Node) 的一个进程, 负责运行 Task
  - 每个进程会派生出很多线程, 每个线程再去执行相关任务
- **Application**: Spark 编写的程序
- **Task**: 运行在 Executor 上的工作单元
- **Job**: 一个 Job 包含多个 RDD 以及作用于相应 RDD 上的各种操作 (RDD + 操作)
- **Stage**: 一个 Job 的基本调度单位. 一个 Job 会分为多组 Task. 每组 Task 被称为 Stage, 或者 TaskSet. 代表了一组关联的, 相互没有 Shuffle 依赖关系的任务组成的任务集合

`我们提交的应用程序会被分为很多作业,每个作业又被分为很多任务, 多个任务的组合就是stage`

![image-20210907110320875](https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20210907110320875.png)

- 一主多从架构

![image-20210907110123061](https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20210907110123061.png)

> **Driver Program** 任务控制节点

> C**luster Manager** (集群资源管理器) 就是用来调度集群中 CPU, 内存, 带宽等等这些资源
>
> 可以用 Spark 自带的作为 Cluster Manager, 同时也可以用 Hadoop Yarn, Mesos 等

Driver Program 向 Cluster Manager 申请资源, 启动 Worker Node 的 Executor. 同时将代码和文件数据发送给 Worker Node, Executor 派生出来的线程就会去执行任务, 然后将执行结果返回给 Driver Program

#### 3.2 运行流程

![image-20210907112201037](https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20210907112201037.png)

- Spark Context 会根据你的 RDD 依赖关系去生成一个 DAG 关系图. 代码会直接在 DAG 上进行操作. DAG 图会交给 DAG Scehduler 进行处理, 将 DAG 图解析成很多个阶段, 每一个阶段 (Stage) 会包括很多个任务.

- Executor 派生出来的线程会向 Task Scheduler 申请运行, 由 Task Scheduler 负责分发

- **计算向数据靠拢**

  - **如果机器 A (带有数据), B, C 同时像 Task Scheduler 申请, 那么 Task Scheduler 会分发给谁呢?**

  - **答案是 A, Task Scheduler 会 check 如果 A 有数据, 那么就会直接发给 A. 否则还得将数据从 A 发给其他的机器**

#### 3.3 RDD 运行原理

> **Hadoop** 不适合处理迭代式的任务, 因为 Hadoop 会将中间数据储存在磁盘中, 下一个子任务会从磁盘中重新读取数据. **磁盘 IO 开销**以及**序列化/反序列化开销**都很大
>
> ![image-20210907145633060](https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20210907145633060.png)
>
> **不同的任务都可以转换成不同的 RDD 之间的转换, 最终都会变成 DAG 依赖关系**
>
> ![image-20210907145743134](https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20210907145743134.png)

- **不同的任务都可以转换成不同的 RDD 之间的转换, 最终都会变成 DAG 依赖关系**,意思就是有向无环图关系, 上次操作结果不需要落入磁盘, 马上可以为下次计算所用, 直到最后输出结果.

##### RDD 操作类型

- RDD有很多操作,但是可以分为两类
  - **Action**: 动作类型操作
  - **Transformation**: 转换类型操作

  ***这两种操作都是粗粒度的修改, 一次只能对 RDD 全集进行修改转换***

> **只能全部修改**, 不可以像 SQL 一样针对某一行对某一列进行转换,就是**只能在转换中修改数据**

##### RDD 执行过程

- RDD 读入外部数据源进行创建
- RDD 经过一系列转换 (Transformation) 操作, 每一次都会产生不同的 RDD 提供给下一次操作使用
- 最后一个 RDD 经过 Action 操作进行转换并输出到外部数据源

##### **RDD 的一些特点**

1. **惰性调用机制**

   Transformation 操作是不会提供结果的, 只是记录转换的过程/轨迹, 并没有发生计算. 只有出发到 Action 操作, 才会真正的触发计算, 比如 `.count()`

   ![image-20210908232204238](https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20210908232204238.png)

2. **天然的容错性**

   Spark 具有天然的容错性, 主要是在 RDD 的转换过程中存在 Lineage 血缘关系, 即在上面的图中 B 是由 A 转换来的, E 又是由 B 和 D 转换来的.

   需要恢复数据的话, 只需要逆过程寻找即可

3. **避免不需要的序列化/反序列化**

   RDD 的中间结果会被持久化到**内存**, `RDD.cache()` 避免了不必要的磁盘读写开销, 数据在内存中多个 RDD 之间进行传递的操作 `RDD.catch()`

#### 3.4 RDD 依赖关系和阶段划分

> 为什么一个作业 (Job) 要分成多个不同的阶段 (Stage) ?
>
> - **窄依赖**: **不**划分阶段, 可以进行 Pipeline 优化
> - **宽依赖**: 划分多个阶段, 不能进行 Pipeline 优化

- 而去区分宽/窄依赖的一个重要的操作就是是否 **Shuffle**操作, 存在Shuffle 操作的就是宽依赖

##### Shuffle操作

1. **在网络中大规模的来回进行的数据传输**
2. **不同节点之间相互传输数据**

##### **宽依赖 & 窄依赖**

- 窄依赖: 一个父 RDD 分区对应一个子 RDD 分区或者 多个父 RDD 分区对应一个 子 RDD 分区

  <img src="https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20210907151942364.png" alt="image-20210907151942364" style="zoom: 33%;" />

- 宽依赖: 一个父 RDD 分区对应多个子 RDD 分区

  <img src="https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20210907152025689.png" alt="image-20210907152025689" style="zoom:33%;" />

##### Spark 优化原理

- 不发生无意义的等待, 但是只要发生 Shuffle (宽依赖) 一定会写磁盘

  - 单个RDD转换

  <img src="https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20210907153904826.png" alt="image-20210907153904826" style="zoom:33%;" />

  - 多个RDD转换,就是多个fork/join

  <img src="https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20210907153916124.png" alt="image-20210907153916124" style="zoom:50%;" />

- **举例: 所有学生从北京飞往厦门**

  - 方案一:

    `方案一是窄依赖,可优化` 

    - 优化前6h:

    <img src="https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20210907154237335.png" alt="image-20210907154237335" style="zoom: 33%;" />

    - 优化后5h(流水线优化):

      <img src="https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20210907154446553.png" alt="image-20210907154446553" style="zoom:33%;" />

  - 方案二:

    `方案二是宽依赖, 无法进行流水线优化`

    - 方案无法优化, 必须落地才能完成人员交换, 发生shuffle操作

      <img src="https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20210907154553324.png" alt="image-20210907154553324" style="zoom:33%;" />

##### **DAG 图反向解析**

- 窄依赖: 不断加入阶段stage
- 宽依赖: 生成不同阶段stage

<img src="https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20210907154936177.png" alt="image-20210907154936177" style="zoom:50%;" />

- 每一个阶段内部都是可以并行处理,流水线化处理, 不需要等待
- 阶段和阶段之间都是发生了等待

##### RDD 运行过程

<img src="https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20210907155319058.png" alt="image-20210907155319058" style="zoom:33%;" />