## Datax 框架设计

- 整体框架

![image-20211015100516190](https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20211015100516190.png) 

- 支持的数据源

  ![image-20211015173425490](https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20211015173425490.png)

- 运行原理

  ![image-20211015174214394](https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20211015174214394.png)

  - Job:单个作业的管理节点，负责数据清理、子任务划分、TaskGroup监控管理。
  - Task:由Job切分而来，是DataX作业的最小单元，每个Task负责一部分数据的同步工作。 
  - Schedule:将Task组成TaskGroup，**单个TaskGroup的并发数量为5**。
  - TaskGroup:负责启动Task。

  ```python
  """
  举例来说，用户提交了一个 DataX 作业，并且配置了 20 个并发，目的是将一个 100 张 分表的 mysql 数据同步到 odps 里面。 DataX 的调度决策思路是:
  1)DataXJob 根据分库分表切分成了 100 个 Task。
  2)根据 20 个并发，DataX 计算共需要分配 4 个 TaskGroup。
  3)4 个 TaskGroup 平分切分好的 100 个 Task，每一个 TaskGroup 负责以 5 个并发共计运
  行25个Task。
  """
  ```

## 与Sqoop对比

![image-20211015174557402](https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20211015174557402.png)

## Datax 扩展 vertica

1. 进入`/apps/datax/plugin/reader/rdbmsreader `目录

2. `vim plugin.json`注册vertica驱动配置

   ```json
   {
       "name": "rdbmsreader",
       "class": "com.alibaba.datax.plugin.reader.rdbmsreader.RdbmsReader",
       "description": "useScene: prod. mechanism: Jdbc connection using the database, execute select sql, retrieve data from the ResultSet. warn: The more you know about the database, the less problems you encounter.",
       "developer": "alibaba",
       "drivers":["com.vertica.jdbc.Driver","dm.jdbc.driver.DmDriver", "com.sybase.jdbc3.jdbc.SybDriver", "com.edb.Driver"]
   }
   ```

3. 将vertica 驱动添加到`/apps/datax/plugin/reader/rdbmsreader/libs`

4. 进入`/apps/datax/plugin/writer/rdbmswriter `目录

5. `vim plugin.json`注册vertica驱动配置

   ```json
   {
       "name": "rdbmswriter",
       "class": "com.alibaba.datax.plugin.reader.rdbmswriter.RdbmsWriter",
       "description": "useScene: prod. mechanism: Jdbc connection using the database, execute select sql, retrieve data from the ResultSet. warn: The more you know about the database, the less problems you encounter.",
       "developer": "alibaba",
       "drivers":["com.vertica.jdbc.Driver","dm.jdbc.driver.DmDriver", "com.sybase.jdbc3.jdbc.SybDriver", "com.edb.Driver"]
   }
   ```

6. 将vertica 驱动添加到`/apps/datax/plugin/writer/rdbmswriter/libs`



## 脏数据处理配置

1. Job Setting配置

```json
{
  "job": {
    "content": [
      {
        "reader": {
          "name": "",
          "parameter": {}
        },
        "writer": {
          "name": "",
          "parameter": {}
        }
      }
    ],
    "setting": {
      "speed": {
        "channel": 1,
        "byte": 104857600
      },
      "errorLimit": {
        "record": 10,
        "percentage": 0.05
      }
    }
  }
}
```

- job.setting.speed(流量控制)
   Job支持用户对速度的自定义控制，channel的值可以控制同步时的并发数，byte的值可以控制同步时的速度。
- job.setting.errorLimit(脏数据控制)
   Job支持用户对于脏数据的自定义监控和告警，包括对脏数据最大记录数阈值（record值）或者脏数据占比阈值（percentage值），当Job传输过程出现的脏数据大于用户指定的数量/百分比，DataX Job报错退出。



## Datax 优化

- **channel** 管道数量
- **record** 记录数
- **byte** 字节数

### 关键参数

- ➢  job.setting.speed.channel: channel 并发数
- ➢  job.setting.speed.record : 全局配置 channel 的 record 限速
- ➢  job.setting.speed.byte: 全局配置 channel 的 byte 限速
- ➢  core.transport.channel.speed.record:单个channel的record限速
- ➢  core.transport.channel.speed.byte:单个channel的byte限速

### 优化1：提升每个channel 速度

- 在 DataX 内部对每个 Channel 会有严格的速度控制，分两种，
  - 一种是控制每秒同步的记 录数 record，
  - 另外一种是每秒同步的字节数，默认的速度限制是 1MB/s，可以根据具体硬件情况设 置这个 byte 速度或者 record 速度，一般设置 byte 速度，比如:我们可以把单个 Channel 的 速度上限配置为 5MB；

### 优化2：提升Job内channel 并发数

- 并发数 = taskGroup 的数量 * 每个 TaskGroup 并发执行的 Task 数 (默认为 5)。 提升 job 内 Channel 并发有三种配置方式:

1. **配置全局** **Byte** **限速以及单** **Channel Byte** **限速**

   Channel 个数 = 全局 Byte 限速 / 单 Channel Byte 限速

   ```json
   {
   	"core": {
   		"transport": {
   			"channel": {
   				"speed": {
   					"byte": 1048576
   				}
   			}
   		} 
   	},
   	"job": {
   		"setting": {
   			"speed": {
   				"byte": 5242880
   			}
   		}
   	}
   }
   ```

   - core.transport.channel.speed.byte=1048576，job.setting.speed.byte=5242880，所以 Channel 个数 = 全局 Byte 限速 / 单 Channel Byte 限速=5242880/1048576=5 个

2. **配置全局** **Record** **限速以及单** **Channel Record** **限速**

   Channel 个数 = 全局 Record 限速 / 单 Channel Record 限速

   ```json
   {
   	"core": {
   		"transport": {
   			"channel": {
   				"speed": {
   					"record": 100
   				}
   			}
   		}
   	},
   	"job": {
   		"setting": {
   			"speed": {
   				"record": 500
   			}
   		}
   	}
   }
   ```

   - core.transport.channel.speed.record=100 ， job.setting.speed.record=500, 所 以 配 置 全 局 Record 限速以及单 Channel Record 限速，Channel 个数 = 全局 Record 限速 / 单 Channel Record 限速=500/100=5

3. **直接配置** **Channel** **个数**

   >**只有在上面两种未设置才生效，上面两个同时设置是取值小的作为最终的 channel 数。**

   ```json
   {
   	"job": {
   		"setting": {
   			"speed": {
   				"channel": 5
   			}
   		}
   	}
   }
   ```

   - 直接配置 job.setting.speed.channel=5，所以 job 内 Channel 并发=5 个

### 优化3：提高 JVM 堆内存

- 当提升 DataX Job 内 Channel 并发数时，内存的占用会显著增加，因为 DataX 作为数据 交换通道，在内存中会缓存较多的数据。例如 Channel 中会有一个 Buffer，作为临时的数据 交换的缓冲区，而在部分 Reader 和 Writer 的中，也会存在一些 Buffer，为了防止 OOM 等错 误，调大 JVM 的堆内存。

- 建议将内存设置为 4G 或者 8G，这个也可以根据实际情况来调整。

  s调整 JVM xms xmx 参数的两种方式:一种是直接更改 datax.py 脚本;另一种是在启动 的时候，加上对应的参数，如下:

  ```python datax/bin/datax.py --jvm="-Xms8G -Xmx8G" XXX.json```
