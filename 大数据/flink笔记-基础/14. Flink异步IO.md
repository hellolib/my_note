> Async I/0是阿里巴巴贡献给社区的一个呼声非常高的特性,于1.2版本引入。主要目的是为了解决与外部系统交互时网络延迟成为了系统瓶颈的问题。

## 1. 异步l0操作的需求

>  flink在做流数据计算时,很多时候需要与外部系统进行交互(比如数据库、Redis、 Hive、 HBase等等存储系统)。往往需要注意系统间通信延迟是否会拖慢整个Flink作业，影响整体吞吐量和实时性。

- 场景:

  流计算系统中经常需要于外部系统进行交互, 比如需要查询外部数据库以关联上用户的额外信息,通常，我们的实现方式是向数据库发送用户a的查询请求(例如在MapFunction中) ，然后等待结果返回，在这之前，我们无法发送用户b的查询请求,这是一种同步访问的模式，如下图左边所示。

  ![image-20220119184505252](https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20220119184505252.png)

- 图中棕色的长条标识等待时间，可以发现网络等待时间极大的阻碍了吞吐和延迟，为了解决同步访问的问题，异步模式可以并发的处理多个请求和回复,也就是说，你可以连续的向数据库发送用户a、b、C、d等的请求，与此同时，哪个请求的回复先返回了就处理哪个回复，从而连续的请求之间不需要阻塞等待,如_上图右边所示，这也正是Async /0的实现原理。

- ![image-20220119185650150](https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20220119185650150.png)

## 2. 使用前提条件

1. 对外部系统进行异步I0访问的客户端API。(此如使用vertx, 但是目前只支持scala 2.12的版本,可以使用java类库来做)

2. 或者在没有这样的客户端的情况下，可以通过创建多个客户端并使用线程池处理同步调用来尝试将同步客户端转变为有限的并发客户端。但是，这种方法通常比适当的异步客户端效率低。(比如可以写ExecutorService来实现)

## 3. Async I/O API实现异步流式转换

> - Async 1/0 API允许用户在数据流中使用异步客户端访问外部存储，该API处理与数据流的集成，以及消息顺序性(Order) ，事件时间(EventTime) ，一致性 (容错)等脏活累活,用户只专注于业务
> - 如果目标数据库中有异步客户端，则三步即可实现异步流式转换操作(针对该数据库的异步) :
>   1. 实现用来份发请求的AsyncFunction,来向数据库发送异步请求并设置回调
>   2. 获取操作结果的callback,并将它提交给ResultFuture
>   3. 将异步I/O操作应用于DataStream

- demo

  > 调用

  ```scala
      // 2. 将订单表关联dim表,实时拉宽 (异步IO)
      // AsyncDataStream.unorderedWait 无序  AsyncDataStream.orderedWait() 有序
      val orderDetailWideEntityDataStream = AsyncDataStream.unorderedWait(
        orderDataStream, // 数据流
        new AsyncOrderDetailRedisRequest(), // 异步请求对象
        1, // 一分钟超时
        TimeUnit.SECONDS,
        100 // 100 个并发请求
      )
  ```

  > 实现 异步IO请求对象

  ```scala
  package com.dcits.realtime.etl.async
  
  import com.alibaba.fastjson.{JSON, JSONObject}
  import com.dcits.realtime.etl.bean.OrderEntity
  import com.dcits.realtime.etl.utils.RedisUtil
  import org.apache.flink.configuration.Configuration
  import org.apache.flink.runtime.concurrent.Executors
  import org.apache.flink.runtime.executiongraph.Execution
  import org.apache.flink.streaming.api.scala.async.{ResultFuture, RichAsyncFunction}
  import redis.clients.jedis.Jedis
  
  import scala.concurrent.{ExecutionContext, Future}
  
  /**
   * 异步查询订单明细数据与维度表数据进行关联
   * dim 数据在redis中, 使用richAsyncFunction
   */
  class AsyncOrderDetailRedisRequest extends RichAsyncFunction[String, OrderEntity] {
    var jedis: Jedis = _
  
    override def open(parameters: Configuration): Unit = {
      super.open(parameters)
      // 获取redis 连接
      jedis = RedisUtil.getJedis
      // 指定redis 数据库索引
      jedis.select(1)
    }
  
    override def close(): Unit = {
      if (jedis.isConnected) {
        jedis.close()
      }
    }
  
    // redis 超时, 重写后执行该方法里的逻辑
    override def timeout(input: String, resultFuture: ResultFuture[OrderEntity]): Unit = {
      println("redis连接超时: 订单操作, redis连接超时")
    }
  
    // 定义异步回调上下文: implicit 隐式转换
    implicit lazy val executor = ExecutionContext.fromExecutor(Executors.directExecutor())
  
    // 异步操作, 对数据流中每一条数据操作, 异步处理
    override def asyncInvoke(input: String, resultFuture: ResultFuture[OrderEntity]): Unit = {
      // 发起异步请求, 获取要结束的future
      Future {
        val inputJsonObj = JSON.parseObject(input)
        // 1. 根据商品id获取商品的详细信息
        val goodsJson = jedis.hget("dim_goods_info", inputJsonObj.getLong("goodsId").toString)
        val dimGoods = JSON.parseObject(goodsJson)
        // 2. 根据city id获取城市详细信息
        val cityJson = jedis.hget("dim_city_info", inputJsonObj.getLong("cityId").toString)
        val dimCity = JSON.parseObject(cityJson)
        println(dimCity)
        // 3. 拉宽数据
        val orderEntity = OrderEntity(
          inputJsonObj.getLong("id"),
          inputJsonObj.getLong("goodsId"),
          dimGoods.getString("goodsName"),
          inputJsonObj.getLong("cityId"),
          dimCity.getString("cityName")
        )
        // 异步请求回调
        resultFuture.complete(Array(orderEntity))
      }
    }
  }
  
  ```



## 4.  Async IO应用于DataStream

- AsyncDataStream是一个工具类， 用于将AsyncFunction应用于DatasStream, AsyncFunction发出的并发请求都是无序的，该顺序基于哪个请求先完成，为了控制结果记录的发出顺序, flink提供 了两种模式，分别对应AsyncDataStream的两个静态方法,OrderedWait和unorderedWait 

  AsyncDataStream.orderedWait();
  AsyncDataStream.unorderWait();

  1. orderedWait (有序) :消息的发送顺序与接收到的顺序相同(包括watermark)，也就是先进先出。
  2. unorderWait (无序) : 
     - 在ProcessingTime中， 完全无序，即哪个请求先返回结果就先发送(最低延迟和最低消耗)。
     - 在EventTime中， 以watermark为边界，介于两个watermark之间的消息可以乱序，但是watermark
       和消息之间不能乱序，这样既认为在无序中又引入了有序，这样就有了与有序-样的开销。

## 5. 原理实现

- AsyncDataStream.(un)orderedWait的主要工作就是创建了一个AsyncWaitOperator。AsyncWaitOperator支持异步I0访问的算子实现，该算子会运行AsyncFunctioh并处理异步返回的结果，内部原理如下图所示。

  ![image-20220119190646969](https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20220119190646969.png)

  - 如图所示，AsyncWaitOperator 主要由两部分组成: StreamElementQueue 和Emitter。
  - StreamElementQueue是- -个Promise队列，所谓Promise是一种异步抽象表示将来会有一个值(海底捞排队给你的小票) ,这个队列是未完成的Promise队列，也就是进行中的请求队列。
  - Emitter 是一个单独的线程，负责发送消息(收到的异步回复)给下游。
  - 图中E5表示进入该算子的第五个元素("Element-5") ，在执行过程中首先会将其包装成一个“Promise" P5,然后将P5放入队列。最后调用AsyncFunction的aynclnvoke方法，该方法会向外部服务发起一个异步的请求,并注册回调。该回调会在异步请求成功返回时调用AsyncCollector.collect方法将返回的结果交给框架处理。
  - 实际上AsyncCollector是一个Promise，也就是P5，在调用collect的时候会标记Promise为完成状态,并通知Emitter线程有完成的消息可以发送了。Emitter 就会从队列中拉取完成的Promise，并从Promise中取出消息发送给下游。

## 6. 消息的顺序性

> 上文提到Async I/0提供了两种输出模式。
>
> 其实细分有三种模式:有序, ProcessingTime 无序, EveNtTime无序。Flink 使用队列来实现不同的输出模式，并抽象出一个队列的接口(StreamElementQueue)， 这种分层设计使得AsyncWaitOperator和Emitter不用关心消息的顺序问题。
>
> StreamElementQueue有两种具体实现，分别是OrderedStreamElementQueue和UnorderedStreamElementQueue。UnorderedStreamElementQueue 比较有意思，它使用了一套逻辑巧妙地实现完全无序和EventTime无序。

### 6.1 有序

> 有序比较简单,使用一个队列就能实现。所有新进入该算子的元素(包括watermark)，都会包装成Promise并按到达顺序放入该队列。

- 如下图所示，尽管P4的结果先返回，但并不会发送，只有P1 (队首)的结果返回了才会触发Emitter 拉取队首元素进行发送。

  ![image-20220119191233910](https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20220119191233910.png)

### 6.2 ProcessingTime无序

- ProcessingTime无序也比较简单,因为没有watermark,不需要协调watermark与消息的顺序性,所以使用两个队列就能实现，一个uncompletedQueue一个completedQueue。所有新进入该算子的元素,同样的包装成Promise并放入uncompletedQueue队列，当uncompletedQueue队列中任意的Promise返回了数据，则将该Promise移到completedQueue队列中，并通知Emitter消费。如图所示:

  <img src="https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20220119191426318.png" alt="image-20220119191426318" style="zoom:50%;" />

### 6.3 EventTime无序

- EventTime无序类似于有序与ProcessingTime无序的结合体。因为有watermark,需要协调watermark与消息之间的顺序性，所以uncompletedQueue中存放的元素从原先的 Promise 变成了Promise集合。

- 如果进入算子的是消息元素，则会包装成Promise放入队尾的集合中。如果进入算子的是watermark,也会包装成Promise并放到一个独立的集合中，再将该集合加入到uncompletedQueue队尾，最后再创建一个空集合加到uncompletedQueue队尾。这样watermark 就成了消息顺序的边界。只有处在队首的集合中的Promise返回了数据，才能将该Promise移到completedQueue队列中，由Emitter消费发往下游。只有队首集合空了，才能处理第二二个集合。这样就保证了当且仅当某个watermark之前所有的消息都已经被发送了，该watermark才能被发送。过程如下图所示:

  <img src="https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20220119191602539.png" alt="image-20220119191602539" style="zoom: 50%;" />