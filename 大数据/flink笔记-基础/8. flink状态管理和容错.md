## 1. flink中的状态

> - 由一个任务维护，并且用来计算某个结果的所有数据，都属于这个任务的状 态
> - 可以认为状态就是一个本地变量，可以被任务的业务逻辑访问
> - Flink 会进行状态管理，包括**状态一致性、故障处理以及高效存储和访问**，以便开发人员可以专注于应用程序的逻辑
> - 在 Flink 中，状态始终与特定算子相关联
> - 为了使运行时的 Flink 了解算子的状态，算子需要预先注册其状态

![image-20220105185128555](https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20220105185128555.png)

- 状态分类
  1. 算子状态（Operator State）: 算子状态的作用范围限定为算子任务
  2. 键控状态（Keyed State）:  根据输入数据流中定义的键（key）来维护和访问

## 2. 算子状态 (Operatior State)

> - 算子状态的作用范围限定为算子任务，由同一并行任务所处理的所有数据都 可以访问到相同的状态
> - 状态对于同一子任务而言是共享的
> - 算子状态不能由相同或不同算子的另一个子任务访问
> - 不常用,  常用的是键控状态

<img src="https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20220105185703099.png" alt="image-20220105185703099" style="zoom:50%;" />

- 算子状态的数据结构
  - 列表状态（List state）将状态表示为一组数据的列表
  - 联合列表状态（Union list state）也将状态表示为数据的列表。它与常规列表状态的区别在于，在发生故 障时，或者从保存点（savepoint）启动应用程序时如何恢复
  - 广播状态（Broadcast state）如果一个算子有多项任务，而它的每项任务状态又都相同，那么这种特 殊情况最适合应用广播状态。

## 3. 键控状态 (Keyed State)

> - 键控状态是根据输入数据流中定义的键（key）来维护和访问的
> - Flink 为每个 key 维护一个状态实例，并将具有相同键的所有数据，都分区到 同一个算子任务中，这个任务会维护和处理这个 key 对应的状态
> -  当任务处理一条数据时，它会自动将状态的访问范围限定为当前数据的 key
> -  键控状态必须在keyby之后使用, 也就是只有KeyedStream才能使用键控状态方法

<img src="https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20220105190357577.png" alt="image-20220105190357577" style="zoom:50%;" />

- 键控状态数据结构

  - 值状态（Value state） 将状态表示为单个的值

  - 列表状态（List state）将状态表示为一组数据的列表
  - 映射状态（Map state）将状态表示为一组 Key-Value 对
  - 聚合状态（Reducing state & Aggregating State）将状态表示为一个用于聚合操作的列表

### 3.1 键控状态使用

> 定义是时候必须自定义在RichFunction中 , 应为需要使用上下文.

1. 声明一个键控状态

   ![image-20220105190628561](https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20220105190628561.png)

2. 读取状态

   ![image-20220105190644124](https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20220105190644124.png)

3. 对状态赋值

   ![image-20220105190654878](https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20220105190654878.png)

- demo

  ```scala
  
  // Keyed state测试：必须定义在RichFunction中，因为需要运行时上下文
  class CustomRichMapper extends RichMapFunction[SensorReading, String]{
  
    var valueState: ValueState[Double] = _  // 方式1: 因为要使用上下文, 在open函数之前定义
    
    // 方式2: lazy 修饰会在调用的时候执行
    lazy val listState: ListState[Int] = getRuntimeContext.getListState( new ListStateDescriptor[Int]("liststate", classOf[Int]) )
    lazy val mapState: MapState[String, Double] = getRuntimeContext.getMapState( new MapStateDescriptor[String, Double]("mapstate", classOf[String], classOf[Double]))
    lazy val reduceState: ReducingState[SensorReading] = getRuntimeContext.getReducingState(new ReducingStateDescriptor[SensorReading]("reducestate", new MyReducer, classOf[SensorReading]))
  
    override def open(parameters: Configuration): Unit = {
      valueState = getRuntimeContext.getState( new ValueStateDescriptor[Double]("valuestate", classOf[Double]))
    }
  
    override def map(value: SensorReading): String = {
      // 状态的读写
      val myV = valueState.value()
      valueState.update(value.temperature)
      listState.add(1)
      val list = new util.ArrayList[Int]()
      list.add(2)
      list.add(3)
      listState.addAll(list)
      listState.update(list)
      listState.get()
  
      mapState.contains("sensor_1")
      mapState.get("sensor_1")
      mapState.put("sensor_1", 1.3)
  
      reduceState.get()
      reduceState.add(value)
  
      value.id
    }
  }
  
  ```
  

### 3.2 键控状态编程 demo

1. demo1

   > - 需求: 上一时刻的温度和本时刻温度相差值如果大于10度报警(// 需求：对于温度传感器温度值跳变，超过10度，报警)
   > - 具体实现: 
   >   - 可以使用reduce实现, 但是reduce 使用具有局限性, 只能保存数据, 而不能输出报警信息
   >   - 使用keyedStatue `RichFlatmapFunction`实现报警

   ```scala
   package com.atguigu.stateTest
   
   import org.apache.flink.api.common.functions.{RichFlatMapFunction, RichMapFunction}
   import org.apache.flink.api.common.state.{ListState, ListStateDescriptor, MapState, MapStateDescriptor, ReducingState, ReducingStateDescriptor, ValueState, ValueStateDescriptor}
   import org.apache.flink.configuration.Configuration
   import org.apache.flink.streaming.api.TimeCharacteristic
   import org.apache.flink.streaming.api.scala.StreamExecutionEnvironment
   import org.apache.flink.streaming.api.scala._
   import org.apache.flink.util.Collector
   
   import java.util
   
   
   /**
    * 创建样例类, 温度传感器 sensor
    */
   case class SensorReading(id: String, timestamp: Long, temperature: Double)
   
   
   object KeyedStateTest {
     def main(args: Array[String]): Unit = {
       val env = StreamExecutionEnvironment.getExecutionEnvironment
       //    env.setParallelism(1) 
       env.getConfig.setAutoWatermarkInterval(200) // 默认200ms
       env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)
       // 1. 从socket中接收数据
       val socketStream = env.socketTextStream("127.0.0.1", 7777)
       val dataStream = socketStream
         .map(data => {
           val arr = data.split(",")
           SensorReading(id = arr(0), timestamp = arr(1).trim.toLong, temperature = arr(2).trim.toDouble)
         })
       // 需求：对于温度传感器温度值跳变，超过10度，报警(keyedState 键控状态管理实现)
       val alterDataStream = dataStream
         .keyBy(_.id)
         .flatMap(new TempChangeAlert(10.0))
   
       alterDataStream.print("alter data")
       dataStream.print("all data")
       env.execute("keyed state test")
     }
   }
   
   // // 实现自定义RichFlatmapFunction
   class TempChangeAlert(threshold: Double) extends RichFlatMapFunction[SensorReading, (String, Double, Double)] {
     // 定义状态保存上一次的温度值
     lazy val lastTempState: ValueState[Double] = getRuntimeContext.getState(
       new ValueStateDescriptor[Double]("last-temp", classOf[Double])
     )
     // 解决 第一次执行 lastTemp为0 , 直接报警的bug
     lazy val flagState: ValueState[Boolean] = getRuntimeContext.getState(
       new ValueStateDescriptor[Boolean]("flag", classOf[Boolean])
     )
     override def flatMap(inValue: SensorReading, outCollector: Collector[(String, Double, Double)]): Unit = {
       // 获取上次的温度
       val lastTemp = lastTempState.value()
       // 跟最新的温度值求差值作比较
       val diff = (inValue.temperature-lastTemp).abs
       if (flagState.value() && diff >= threshold ){
         // 输出报警信息
         outCollector.collect((inValue.id,lastTemp,inValue.temperature))
       }
       // 更新状态, 更新本次新的温度值, 供下次比较
       lastTempState.update(inValue.temperature)
       flagState.update(true)
     }
   }
   
   
   ```

   

2. demo2: demo1 的简单写法

   ```scala
   package com.atguigu.stateTest
   
   import org.apache.flink.api.common.functions.{RichFlatMapFunction, RichMapFunction}
   import org.apache.flink.api.common.state.{ListState, ListStateDescriptor, MapState, MapStateDescriptor, ReducingState, ReducingStateDescriptor, ValueState, ValueStateDescriptor}
   import org.apache.flink.configuration.Configuration
   import org.apache.flink.streaming.api.TimeCharacteristic
   import org.apache.flink.streaming.api.scala.StreamExecutionEnvironment
   import org.apache.flink.streaming.api.scala._
   import org.apache.flink.util.Collector
   
   import java.util
   
   
   /**
    * 创建样例类, 温度传感器 sensor
    */
   case class SensorReading(id: String, timestamp: Long, temperature: Double)
   
   
   object KeyedStateTest {
     def main(args: Array[String]): Unit = {
       val env = StreamExecutionEnvironment.getExecutionEnvironment
       //    env.setParallelism(1)
       env.getConfig.setAutoWatermarkInterval(200) // 默认200ms
       env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)
       // 1. 从socket中接收数据
       val socketStream = env.socketTextStream("127.0.0.1", 7777)
       val dataStream = socketStream
         .map(data => {
           val arr = data.split(",")
           SensorReading(id = arr(0), timestamp = arr(1).trim.toLong, temperature = arr(2).trim.toDouble)
         })
       // 需求：对于温度传感器温度值跳变，超过10度，报警(keyedState 键控状态管理实现)
       val alterDataStream = dataStream
         .keyBy(_.id)
         //      .flatMap(new TempChangeAlert(10.0))
         .flatMapWithState[(String, Double, Double), Double] { // 参数类型(String, Double, Double) 为返回数据类型,, Double为状态保存类型
           // 如果第一条温度进入, 上次温度为None, 则返回一个空list, 然后记录上一次温度值(some()为option类型)
           case (data: SensorReading, None) => (List.empty, Some(data.temperature))
           //
           case (data: SensorReading, lastTemp: Option[Double]) => {
             // 跟最新的温度值求差值作比较
             val diff = (data.temperature - lastTemp.get).abs
             if (diff >= 10.0) {
               // 输出报警信息
               (List((data.id, lastTemp.get, data.temperature)), Some(data.temperature))
             } else {
               (List.empty, Some(data.temperature))
             }
           }
         }
       alterDataStream.print("alter data")
       env.execute("keyed state test")
     }
   }
   
   ```
   
   

## 4. 状态后端 (State Backends)

> - 每传入一条数据，有状态的算子任务都会读取和更新状态
> - 由于有效的状态访问对于处理数据的低延迟至关重要，因此每个并行 任务都会在本地维护其状态，以确保快速的状态访问
> - **状态的存储、访问以及维护，由一个可插入的组件决定，这个组件就 叫做状态后端（state backend）**
> - 状态后端主要负责两件事：
>   - 本地的状态管理
>   - 将检查点 （checkpoint）状态写入远程存储
    <img src="https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20220107134733717.png" style="zoom: 33%;" />

- 选择一个状态后端:

  1. MemoryStateBackend

     - 内存级的状态后端，会将键控状态作为内存中的对象进行管理，将它们存储在 TaskManager 的 JVM 堆上，而将 checkpoint 存储在 JobManager 的内存中
     - 特点：快速、低延迟，但不稳定
     - 测试调试使用, 开发环境中默认是MemoryStateBackend

  2. FsStateBackend

     - 将 checkpoint 存到远程的持久化文件系统（FileSystem）上，而对于本地状态， 跟 MemoryStateBackend 一样，也会存在 TaskManager 的 JVM 堆上
     - 同时拥有内存级的本地访问速度，和更好的容错保证
     - 测试调试使用

  3. **RocksDBStateBackend**

     - 将所有状态序列化后，存入本地的 RocksDB 中存储。

     - RocksDB 内嵌的key/value 数据库

     - 生产使用

     - 注意：RocksDB 的支持并不直接包含在 flink 中， 需要引入依赖

       ```xml
       <dependency>
       
       <groupId>org.apache.flink</groupId>
       
       <artifactId>flink-statebackend-rocksdb_2.12</artifactId>
       
       <version>1.10.1</version>
       
       </dependency>
       ```

       

- demo: **RocksDBStateBackend**

  ```scala
  val env = StreamExecutionEnvironment.getExecutionEnvironment 
  
  val checkpointPath: String = ???
  
  val backend = new RocksDBStateBackend(checkpointPath)
  
  env.setStateBackend(backend)   // RocksDBStateBackend
  env.setStateBackend(new FsStateBackend("file:///tmp/checkpoints"))    // FsStateBackend 
  env.enableCheckpointing(1000) // 配置重启策略 
  env.setRestartStrategy(RestartStrategies.fixedDelayRestart(60, Time.of(10, TimeUnit.SECONDS)))
  ```

  

## 5. 容错机制

> exactly once  精确一次保存检查点, 不再重复计算
>
> AT_LEAST_ONCE  速度更快, 精确不如 exactly once 
>
> 大佬参考文章: https://zhuanlan.zhihu.com/p/104601440

### 5.1 一致性检查点（checkpoint）

> - Flink 故障恢复机制的核心，就是应用状态的一致性检查点
> - **有状态流应用的一致检查点，其实就是所有任务的状态，在某个时间点的一份 拷贝（一份快照**）；这个时间点，应该是所有任务都恰好处理完一个相同的输 入数据的时候

<img src="https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20220107135921136.png" alt="image-20220107135921136" style="zoom: 50%;" />

- checkpoint 设置

  - 默认关闭, 需要手动打开

  ```scala
      env.enableCheckpointing(interval = 500L,mode = CheckpointingMode.EXACTLY_ONCE) // 打开一致性检查点设置, 默认500ms,EXACTLY_ONCE
      env.getCheckpointConfig.setCheckpointInterval(1000L) // 修改checkpoint 周期
      env.getCheckpointConfig.setCheckpointTimeout(60000L) // 修改 timeout , 超过1min超时
  		env.getCheckpointConfig.enableExternalizedCheckpoints(
        CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION
      ) // 当前作业被取消的时候, 保留之前的checkPoint, 避免数据丢失
  //    env.getCheckpointConfig.setCheckpointingMode(CheckpointingMode.AT_LEAST_ONCE)  // 修改 check mode
  //    env.getCheckpointConfig.setMaxConcurrentCheckpoints(1) // 默认为1 , 设置最大允许几个check point 同时进行
      // env.getCheckpointConfig.setMinPauseBetweenCheckpoints(500L) // 默认为, 设置两个check point之间的间隔最小时间, 如果配置setMaxConcurrentCheckpoints不生效
  //    env.getCheckpointConfig.setPreferCheckpointForRecovery(true)   // 默认为false checkpoint+ savepoint 结合, 如果为True , 更倾向于使用checkpoint 做故障恢复.
  //    env.getCheckpointConfig.setTolerableCheckpointFailureNumber(0)  // 容忍多少次 checkpoint 失败, 默认为0
      env.getCheckpointConfig.setCheckpointTimeout(3600*1000) // 超时时间1小时
  
  
  ```
  
  

### 5.2 从检查点恢复状态

![image-20220107140159082](https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20220107140159082.png)

- 在执行流应用程序期间，Flink 会定期保存状态的一致检查点

- 如果发生故障， Flink 将会使用最近的检查点来一致恢复应用程序的状态，并重新启动处理流程

  1. 遇到故障之后，第一步就是重启应用

     ![image-20220107140556071](https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20220107140556071.png)

  2. 第二步是从 checkpoint 中读取状态，将状态重置: 从检查点重新启动应用程序后，其内部状态与检查点完成时的状态完全相同

     <img src="https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20220107140633718.png" alt="image-20220107140633718" style="zoom: 33%;" />

  3. 第三步：**开始消费并处理检查点到发生故障之间的所有数据**

     ![image-20220530164840531](https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20220530164840531.png)

- 这种检查点的保存和恢复机制可以为应用程序状态提供“精确一次”（exactly once）的一致性，因为所有算子都会保存检查点并恢复其所有状态，这样一 来所有的输入流就都会被重置到检查点完成时的位置



### 5.3 Flink 检查点算法

> - Flink 的检查点算法用到了一种称为分界线（barrier）的特殊数据形式， 用来把一条流上数据按照不同的检查点分开
> - 分界线之前到来的数据导致的状态更改，都会被包含在当前分界线所属 的检查点中；而基于分界线之后的数据导致的所有更改，就会被包含在 之后的检查点中

...

### 5.4 保存点（save points）

- Flink 还提供了可以自定义的镜像保存功能，就是保存点（savepoints）
- 原则上，创建保存点使用的算法与检查点完全相同，因此保存点可以认 为就是具有一些额外元数据的检查点
- Flink不会自动创建保存点，因此用户（或者外部调度程序）必须明确地 触发创建操作
- 保存点是一个强大的功能。除了故障恢复外，保存点可以用于：有计划 的手动备份，更新应用程序，版本迁移，暂停和重启应用，等等



## 6. 容错 重启策略

> 故障重启
>
> 默认是一直重启

```scala
    env.setRestartStrategy(RestartStrategies.fixedDelayRestart(3,5000L)) // 固定时间间隔重启, 5s重启一次, 重启3次
    env.setRestartStrategy(RestartStrategies.failureRateRestart(5,Time.minutes(5),Time.minutes(10)))  //失败率5次, 失败间隔, 两次尝试重启间隔
```

