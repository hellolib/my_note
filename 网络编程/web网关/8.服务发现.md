# 一. 服务发现

> 服务发现是指用注册中心来记录服务信息，以便其他服 务快速査找已注册服务。

- 服务发现分类

  1. **客户端服务发现**

     ![image-20230512192648537](https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-01/20230512192648.png)

  2. **服务端服务发现**

     ![image-20230512192703578](https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-01/20230512192703.png)

  3. **网关实现客户端服务发现**

     > 网关客户端的服务发现并不是请求的客户端, 而是网关主动探测(服务发现模块)客户端
     >
     > 1. 每一个服务启动时都会提供对应的接口或者grpc调用接口,
     > 2. 服务发现模块(客户端)会请求健康检查接口进行健康检查,判断服务可用性
     
     
     
     <img src="https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20211211200733595.png" alt="image-20211211200733595" style="zoom:50%;" />



## 1. 注册中心选型

- 大牛博客:[四种注册中心特点超全总结](https://mp.weixin.qq.com/s?__biz=Mzg5ODA5NDIyNQ==&mid=2247485271&idx=1&sn=84ca5c86588b6bfc193257fe03a14135&chksm=c06682a9f7110bbf4cee08f93539aa32e5b576b3444b0af3e5ceec6a3dc7a544e0ef8a8b33b5&scene=126&sessionid=1605521665&key=55fa9b33dfce44d041a4f74a88d5fe2e1ec37fcebfc939b64da52fdf06ecdad58066ef5197f941b1b5ce415e5575eb3b07c41af0029518c9084a2ee72ab12956a84445537b167ade959c3e175378ca43b80737471accae2998f03224387daaedcdab97260e98e64c896c70e42fd5e44490c8a3e477cf6fcf1989e877f931e3f0&ascene=1&uin=MjAzOTkwMzU2MA%3D%3D&devicetype=Windows+7+x64&version=6300002f&lang=zh_CN&exportkey=ASGc4SPHwpjleREXcm9m1NM%3D&pass_ticket=M%2FcSQ8Vp7xhvenN0CKMlMa%2B5oMoc7JQvdFxsBiYgI8R4wOBQ2jOnLTRYWT8O4Zth&wx_header=0)

- 摘抄

  | 注册中心  | cap特性 | 推荐规模（机器实例数） | 特点                                                         |
  | --------- | ------- | ---------------------- | ------------------------------------------------------------ |
  | eurake    | ap      | <30k                   | 拉取全部节点信息,客户端默认5秒拉取一次                       |
  | zookeeper | cp      | <30k                   | 拉取监听需要的节点信息                                       |
  | nacos     | ap/cp   | 100k-200k              | 长轮询30秒拉一次，每29.5秒返回加上传输损耗时间保持在30秒左右，有变化长轮询直接返回 |
  | consul    | ap/cp   | <5k                    | 拉取全部节点信息 客户端默认3秒拉取一次，每隔1秒拉一次，超时时间2秒 |

   

  | 序号 | 比较项                       | Eureka               | zookeeper                     | Nacos                       | Consul                          |
  | ---- | ---------------------------- | -------------------- | ----------------------------- | --------------------------- | ------------------------------- |
  | 1    | 集群结构                     | 平级                 | 主从                          | 支持平级和主从              | 主从                            |
  | 2    | 集群角色                     | 主人                 | Leader、follower observer     | leader、follower、candidate | server-leader、server以及client |
  | 3    | 是否可以及时知道服务状态变化 | 不能及时知道         | 会及时知道                    | 不能及时知道                | 不能及时知道                    |
  | 4    | 一致性协议（**CAP****）**    | 注重可用性（AP）     | 注重一致性(CP)                | 支持CP和AP-如何实现         | 注重一致性(CP)                  |
  | 5    | 雪崩保护                     | 有                   | 没有                          | 有                          | 没有                            |
  | 6    | 社区是否活跃                 | Eureka2.0不再维护了  | 持续维护                      | 持续维护                    | 持续维护                        |
  | 7    | 管理端                       | 有现成的eureka管理端 | 没有现成的管理端              | 有现成的管理端              | 有现成的管理端                  |
  | 8    | 负载均衡策略                 | 使用ribbon实现       | 一般可以直接采用RPC的负载均衡 | 权重/metadata/Selector      | Fabio                           |
  | 9    | 权限控制                     | 无                   | 使用ACL实现节点权限控制       | RBAC-用户、角色、权限       | ACL                             |
  | 10   | Spring Cloud集成             | 支持                 | 支持                          | 支持                        | 支持                            |
  | 11   | 健康检查                     | Client Beat          | Keep Alive                    | TCP/HTTP/MYSQL/Client Beat  | TCP/HTTP/gRPC/Cmd               |
  | 12   | 自动注销实例                 | 支持                 | 支持                          | 支持                        | 不支持                          |
  | 13   | 访问协议                     | HTTP                 | TCP                           | HTTP/DNS                    | HTTP/DNS                        |
  | 14   | 是否可用作配置中心           | 否                   | 是                            | 是                          | 是                              |
  | 15   | 多数据中心                   | 不支持               | 不支持                        | 不支持                      | 支持                            |
  | 16   | 跨注册中心同步               | 不支持               | 不支持                        | 支持                        | 支持                            |
  | 17   | Dubbo集成                    | 不支持               | 支持                          | 支持                        | 不支持                          |
  | 18   | K8S集成                      | 支持                 | 支持                          | 支持                        | 支持                            |





>服务注册: 把服务注册到注册中心Consul
>
>服务发现: 注册中心发现已注册的服务

- Api 接口: https://www.consul.io/api-docs/agent/service#register-service

## 2. consul

### 2.1 docker安装consul

```sh
docker pull consul  # 拉取镜像

docker run -d -p 8500:8500 -p 8300:8300 -p 8301:8301 -p 8302:8302 -p 8600:8600/udp consul consul agent -dev -client=0.0.0.0  # 启动容器

docker container update --restart=always 容器名字 # 自动重启容器
```

- consul web 端口号 0.0.0.0:8500

- Dns 服务端口 8600
  - 检测8600 是否正常`dig @127.0.0.1 -p 8600 consul.service.consul SRV`

### 2.2 consul  api接口

1、添加服务

- [https://www.consul.io/api-docs/agent/service#register-service](https://links.jianshu.com/go?to=https%3A%2F%2Fwww.consul.io%2Fapi-docs%2Fagent%2Fservice%23register-service)

2、删除服务

- [https://www.consul.io/api-docs/agent/service#deregister-service](https://links.jianshu.com/go?to=https%3A%2F%2Fwww.consul.io%2Fapi-docs%2Fagent%2Fservice%23deregister-service)

3、设置健康检查

- [https://www.consul.io/api-docs/agent/check](https://links.jianshu.com/go?to=https%3A%2F%2Fwww.consul.io%2Fapi-docs%2Fagent%2Fcheck)

4、同一个服务注册多个实例（做负载均衡）

- 注册时，name参数一致，id不一致就ok了

5、获取服务

- [https://www.consul.io/api-docs/agent/service](



## 3. zookeeper

- zookeeper=文件系统+监听通知机制。 

- ZooKeeper 是 Apache 软件基金会的一个软件项目，它为大型分布式计算提供开源的分布式配置服务、同步服务和命名注册。

- 分布式应用程序可以基于它实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能。

- zookkeeper 提供的名称空间非常类似于标准文件系统，key-value 的形式存储。名称 key 由斜线 **/** 分割的一系列路径元素，**zookeeper 名称空间中的每个节点都是由一个路径标识。**

  <img src="https://www.runoob.com/wp-content/uploads/2020/09/zknamespace.jpg" alt="img" style="zoom:50%;" />

- 每一个节点下都可以再创建子节点以及本身的属性

### 3.1 zookeeper 节点类型

![img](https://img-blog.csdn.net/201807121434154?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2phdmFfNjY2NjY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

1. **持久化目录节点**

   客户端与zookeeper断开连接后，该节点依旧存在

2. **持久化顺序编号目录节点**

   客户端与zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号

3. **临时目录节点**

   客户端与zookeeper断开连接后，该节点被删除

4. **临时顺序编号目录节点**

   客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号

### 3.2 zookeeper 单机安装

1. 下载安装包并解压`https://downloads.apache.org/zookeeper`

   ```sh
   wget https://downloads.apache.org/zookeeper/zookeeper-3.5.9/apache-zookeeper-3.5.9-bin.tar.gz
   tar -zxvf apache-zookeeper-3.5.9-bin.tar.gz
   cd apache-zookeeper-3.5.9
   ```

2. 编辑`conf/zoo.cfg`

   ```sh
   tickTime=2000
   dataDir=/var/lib/zookeeper
   clientPort=2181
   admin.serverPort=8888 // 管理端口
   ```

3. 运行`bin/zkServer.sh start`

### 3.3 zookeeper 增删改查

> 一库 "github.com/samuel/go-zookeeper/zk"

```go
package main

import (
	"fmt"
	"github.com/samuel/go-zookeeper/zk"
	"time"
)

var (
	host = []string{"101.201.211.113:2181"}
)

func main() {
	conn, _, err := zk.Connect(host, 5*time.Second)
	if err != nil {
		panic(err)
	}

	//增
	if _, err := conn.Create("/test_tree2", []byte("tree_content"),
		0, zk.WorldACL(zk.PermAll)); err != nil {
		fmt.Println("create err", err)
	}

	//查
	nodeValue, dStat, err := conn.Get("/test_tree2")
	if err != nil {
		fmt.Println("get err", err)
		return
	}
	fmt.Println("nodeValue", string(nodeValue))

	//改
	if _, err := conn.Set("/test_tree2", []byte("new_content"),
		dStat.Version); err != nil {
		fmt.Println("update err", err)
	}

	//删除
	_, dStat, _ = conn.Get("/test_tree2")
	if err := conn.Delete("/test_tree2", dStat.Version); err != nil {
		fmt.Println("Delete err", err)
		//return
	}

	//验证存在
	hasNode, _, err := conn.Exists("/test_tree2")
	if err != nil {
		fmt.Println("Exists err", err)
		//return
	}
	fmt.Println("node Exist", hasNode)

	//增加
	if _, err := conn.Create("/test_tree2", []byte("tree_content"),
		0, zk.WorldACL(zk.PermAll)); err != nil {
		fmt.Println("create err", err)
	}

	//设置子节点
	if _, err := conn.Create("/test_tree2/subnode", []byte("node_content"),
		0, zk.WorldACL(zk.PermAll)); err != nil {
		fmt.Println("create err", err)
	}

	//获取子节点列表
	childNodes, _, err := conn.Children("/test_tree2")
	if err != nil {
		fmt.Println("Children err", err)
	}
	fmt.Println("childNodes", childNodes)
}

```

### 3.4 zookeeper监听子节点变化!!!

- wtach.go

  ```go
  /*
   * @date: 2021/12/12
   * @desc: ...
   */
  
  package compose
  
  import (
  	"fmt"
  	"github.com/samuel/go-zookeeper/zk"
  	"time"
  )
  
  type ZkManager struct {
  	hosts      []string
  	conn       *zk.Conn
  	pathPrefix string
  }
  
  func NewZkManager(hosts []string) *ZkManager {
  	return &ZkManager{
  		hosts:      hosts,
  		pathPrefix: "/gateway_servers_",
  	}
  }
  
  // BuildConnect 创建连接
  func (z *ZkManager) BuildConnect() error {
  	conn, _, err := zk.Connect(z.hosts, 5*time.Second)
  	if err != nil {
  		return err
  	}
  	z.conn = conn
  	return nil
  }
  
  // Close 关闭连接
  func (z *ZkManager) Close() {
  	z.conn.Close()
  	return
  }
  
  // GetPathData 获取配置
  func (z *ZkManager) GetPathData(nodePath string) ([]byte, *zk.Stat, error) {
  	return z.conn.Get(nodePath)
  }
  
  // 更新配置
  
  func (z *ZkManager) SetPathData(nodePath string, config []byte, version int32) (err error) {
  	ex, _, _ := z.conn.Exists(nodePath)
  	if !ex {
  		_, err = z.conn.Create(nodePath, config, 0, zk.WorldACL(zk.PermAll))
  		return err
  	}
  	_, dStat, err := z.GetPathData(nodePath)
  	if err != nil {
  		return err
  	}
  	_, err = z.conn.Set(nodePath, config, dStat.Version)
  	if err != nil {
  		fmt.Println("Update node error", err)
  		return err
  	}
  	fmt.Println("SetData ok")
  	return
  
  }
  
  // RegisterServerPath 创建临时节点
  func (z *ZkManager) RegisterServerPath(nodePath, host string) error {
  	ex, _, err := z.conn.Exists(nodePath)
  	if err != nil {
  		return err
  	}
  	// 依赖节点必须持久化
  	if !ex {
  		_, err = z.conn.Create(nodePath, nil, 0, zk.WorldACL(zk.PermAll))
  		if err != nil {
  			fmt.Println("Create error", nodePath)
  			return err
  		}
  	}
  	// 临时节点
  	subNodePath := nodePath + "/" + host
  	ex, _, err = z.conn.Exists(subNodePath)
  	if err != nil {
  		fmt.Println("Exists error", subNodePath)
  		return err
  	}
  	if !ex {
  		_, err = z.conn.Create(subNodePath, nil, zk.FlagEphemeral, zk.WorldACL(zk.PermAll))
  		if err != nil {
  			fmt.Println("Create error", subNodePath)
  			return err
  		}
  	}
  	return nil
  }
  
  // GetServerListByPath 获取服务器列表
  func (z *ZkManager) GetServerListByPath(path string) (serverList []string, err error) {
  	serverList, _, err = z.conn.Children(path)
  	return serverList, err
  }
  
  // WatchServerListByPath watch机制，服务器有断开或者重连，收到消息
  func (z *ZkManager) WatchServerListByPath(nodePath string) (chan []string, chan error) {
  	conn := z.conn
  	snapshots := make(chan []string) // 快照
  	errors := make(chan error)
  	go func() {
  		for {
  			dataBuf, _, events, err := conn.ChildrenW(nodePath)
  			if err != nil {
  				errors <- err
  				return
  			}
  			snapshots <- dataBuf
  			select {
  			case evt := <-events:
  				if evt.Err != nil {
  					errors <- evt.Err
  				}
  				fmt.Printf("ChildrenW Event Path:%v, Type:%v\n", evt.Path, evt.Type)
  			}
  		}
  
  	}()
  	return snapshots, errors
  }
  
  // WatchPathData watch机制，监听节点值变化
  func (z *ZkManager) WatchPathData(nodePath string) (chan []byte, chan error) {
  	conn := z.conn
  	snapshots := make(chan []byte)
  	errors := make(chan error)
  
  	go func() {
  		for {
  			dataBuf, _, events, err := conn.GetW(nodePath)
  			if err != nil {
  				errors <- err
  				return
  			}
  			snapshots <- dataBuf
  			select {
  			case evt := <-events:
  				if evt.Err != nil {
  					errors <- evt.Err
  					return
  				}
  				fmt.Printf("GetW Event Path:%v, Type:%v\n", evt.Path, evt.Type)
  			}
  		}
  	}()
  	return snapshots, errors
  }
  
  ```

- main.go

  ```go
  package main
  
  import (
  	"fmt"
  	"gatewayTest/gateWareDemo/zookeeper/compose"
  	"log"
  	"os"
  	"os/signal"
  	"syscall"
  )
  
  var addr = "127.0.0.1:2002"
  
  func main() {
  	//获取zk节点列表
  	zkManager := compose.NewZkManager([]string{"101.201.211.113:2181"})
  	zkManager.BuildConnect()
  	defer zkManager.Close()
  
  	zList, err := zkManager.GetServerListByPath("/real_server")
  	fmt.Println("server node:")
  	fmt.Println(zList)
  	if err != nil {
  		log.Println(err)
  	}
  
  	//动态监听节点变化
  	chanList, chanErr := zkManager.WatchServerListByPath("/real_server")
  	defer close(chanList)
  	defer close(chanErr)
  	go func() {
  		for {
  			select {
  			case changeErr := <-chanErr:
  				fmt.Println("changeErr")
  				fmt.Println(changeErr)
  			case changedList := <-chanList:
  				fmt.Println("watch node changed")
  				fmt.Println(changedList)
  			}
  		}
  	}()
  
  	//获取节点内容
  	zc, _, err := zkManager.GetPathData("/rs_server_conf")
  	if err != nil {
  		log.Println(err)
  	}
  	fmt.Println("get node data:")
  	fmt.Println(string(zc))
  
  	//动态监听节点内容
  	dataChan, dataErrChan := zkManager.WatchPathData("/rs_server_conf")
  	defer close(dataChan)
  	defer close(dataErrChan)
  	go func() {
  		for {
  			select {
  			case changeErr := <-dataErrChan:
  				fmt.Println("changeErr")
  				fmt.Println(changeErr)
  			case changedData := <-dataChan:
  				fmt.Println("WatchGetData changed")
  				fmt.Println(string(changedData))
  			}
  		}
  	}()
  
  	//关闭信号监听
  	quit := make(chan os.Signal)
  	signal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)
  	<-quit
  }
  
  ```

  

# 二. 网关实现服务端的服务发现

> 1. 网关从zk中获取可用服务节点, 维护一个列表做负载均衡
> 2. 服务启动时在zk中创建临时节点,节点名和内容为服务地址
> 3. 网关监听zk中的服务, 并更新负载均衡可用服务列表

<img src="https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20211212011745433.png" alt="image-20211212011745433" style="zoom:40%;" />

## 1. 网关扩展服务发现

> 启动时注册服务地址, 然后zookeeper 自动监听发现服务变换

```go
func (r *RealServer) Run() {
	log.Println("Starting httpserver at " + r.Addr)
	mux := http.NewServeMux()
	mux.HandleFunc("/", r.HelloHandler)
	mux.HandleFunc("/base/error",r.ErrorHandler)
	server := &http.Server{
		Addr: r.Addr,
		WriteTimeout: time.Second*3,
		Handler: mux,
	}
	go func() {
		// 注册zk节点
		zkManager:= compose.NewZkManager([]string{"101.201.211.113:2181"})
		err:=zkManager.BuildConnect()
		if err != nil {
			fmt.Printf(" connect zk error: %s ", err)
			panic(err)
		}
		defer zkManager.Close()
		err = zkManager.RegisterServerPath("/real_server", r.Addr)
		if err != nil {
			fmt.Printf(" regist node error: %s ", err)
			panic(err)
		}
		zList,err:= zkManager.GetServerListByPath("/real_server")
		fmt.Println(zList)
		log.Fatal(server.ListenAndServe())
	}()
}
```



## 2. 以观察者模式构建负载均衡配置

![image-20211212020225498](https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20211212020225498.png)

- conf.go

  ```go
  /*
   * @date: 2021/12/12
   * @desc: ...
   */
  
  package loadBalance
  
  import (
  	"fmt"
  	"gatewayTest/gateWareDemo/zookeeper/compose"
  )
  
  type Observer interface {
  	Update()
  }
  
  // LoadBalanceConf 配置主题
  type LoadBalanceConf interface {
  	Attach(o Observer)
  	GetConf() []string
  	WatchConf()
  	UpdateConf(conf []string)
  }
  
  type LoadBalanceZkConf struct {
  	observers    []Observer
  	path         string
  	zkHosts      []string
  	confIpWeight map[string]string
  	activeList   []string
  	format       string
  }
  
  func (s *LoadBalanceZkConf) Attach(o Observer) {
  	s.observers = append(s.observers, o)
  }
  
  func (s *LoadBalanceZkConf) NotifyAllObservers() {
  	for _, obs := range s.observers {
  		obs.Update()
  	}
  }
  func (s *LoadBalanceZkConf) GetConf() []string {
  	var confList []string
  	for _, ip := range s.activeList {
  		weight, ok := s.confIpWeight[ip]
  		if !ok {
  			weight = "50" //默认weight
  		}
  		confList = append(confList, fmt.Sprintf(s.format, ip)+","+weight)
  	}
  	return confList
  }
  
  // WatchConf 更新配置时，通知监听者也更新
  func (s *LoadBalanceZkConf) WatchConf() {
  	zkManger := compose.NewZkManager(s.zkHosts)
  	zkManger.BuildConnect()
  	fmt.Println("watchConf")
  	chanList, chanErr:= zkManger.WatchServerListByPath(s.path)
  	go func() {
  		defer zkManger.Close()
  		for {
  			select {
  			case changeErr:= <-chanErr:
  				fmt.Println("changeErr", changeErr)
  			case changedList := <-chanList:
  				fmt.Println("watch node changed")
  				s.UpdateConf(changedList)
  			}
  		}
  	}()
  }
  
  // UpdateConf 更新配置时，通知监听者也更新
  func (s *LoadBalanceZkConf) UpdateConf(conf []string) {
  	s.activeList = conf
  	for _, obs := range s.observers {
  		obs.Update()
  	}
  }
  
  func NewLoadBalanceZkConf(format, path string, zkHosts []string, conf map[string]string) (*LoadBalanceZkConf, error) {
  	zkManager := compose.NewZkManager(zkHosts)
  	zkManager.BuildConnect()
  	defer zkManager.Close()
  	zlist, err := zkManager.GetServerListByPath(path)
  	if err != nil {
  		return nil, err
  	}
  	mConf := &LoadBalanceZkConf{format: format, activeList: zlist, confIpWeight: conf, zkHosts: zkHosts, path: path}
  	mConf.WatchConf()
  	return mConf, nil
  }
  
  type LoadBalanceObserver struct {
  	ModuleConf *LoadBalanceZkConf
  }
  
  func (l *LoadBalanceObserver) Update() {
  	fmt.Println("Update get conf:", l.ModuleConf.GetConf())
  }
  
  func NewLoadBalanceObserver(conf *LoadBalanceZkConf) *LoadBalanceObserver {
  	return &LoadBalanceObserver{
  		ModuleConf: conf,
  	}
  }
  
  
  
  ```

- conf_test.go

  ```go
  /*
   * @date: 2021/12/12
   * @desc: ...
   */
  
  package loadBalance
  
  import (
  	"fmt"
  	"testing"
  )
  
  func TestNewLoadBalanceObserver(t *testing.T) {
  	moduleConf, err := NewLoadBalanceZkConf("%s",
  		"/real_server",
  		[]string{"101.201.211.113:2181"},
  		map[string]string{"127.0.0.1:2003": "20"},
  	)
  	if err != nil {
  		fmt.Println("err", err)
  		return
  	}
  	loadBalanceObserver := NewLoadBalanceObserver(moduleConf)
  	moduleConf.Attach(loadBalanceObserver)
  	moduleConf.UpdateConf([]string{"122.11.11"})
  
  }
  
  ```

# 三. 网关实现客户端的服务发现

> 网关客户端的服务发现并不是请求的客户端, 而是网关主动探测(服务发现模块)客户端
>
> 1. 每一个服务启动时不需要额外操作, 只需要提供对应的健康检查接口
> 2. 服务发现模块(客户端)会请求健康检查接口进行健康检查, 判断服务可用性

<img src="https://raw.githubusercontent.com/hellolib/pictures/main/Typora/pic-00-gitee/image-20211213001455163.png" alt="image-20211213001455163" style="zoom:40%;" />

- main.go

  ```go
  /*
   * @date: 2021/12/12
   * @desc: ...
   */
  
  package loadBalance
  
  import (
  	"fmt"
  	"gatewayTest/gateWareDemo/zookeeper/compose"
  )
  
  type Observer interface {
  	Update()
  }
  
  // LoadBalanceConf 配置主题
  type LoadBalanceConf interface {
  	Attach(o Observer)
  	GetConf() []string
  	WatchConf()
  	UpdateConf(conf []string)
  }
  
  type LoadBalanceZkConf struct {
  	observers    []Observer
  	path         string
  	zkHosts      []string
  	confIpWeight map[string]string
  	activeList   []string
  	format       string
  }
  
  func (s *LoadBalanceZkConf) Attach(o Observer) {
  	s.observers = append(s.observers, o)
  }
  
  func (s *LoadBalanceZkConf) NotifyAllObservers() {
  	for _, obs := range s.observers {
  		obs.Update()
  	}
  }
  func (s *LoadBalanceZkConf) GetConf() []string {
  	var confList []string
  	for _, ip := range s.activeList {
  		weight, ok := s.confIpWeight[ip]
  		if !ok {
  			weight = "50" //默认weight
  		}
  		confList = append(confList, fmt.Sprintf(s.format, ip)+","+weight)
  	}
  	return confList
  }
  
  // WatchConf 更新配置时，通知监听者也更新
  func (s *LoadBalanceZkConf) WatchConf() {
  	zkManger := compose.NewZkManager(s.zkHosts)
  	zkManger.BuildConnect()
  	fmt.Println("watchConf")
  	chanList, chanErr:= zkManger.WatchServerListByPath(s.path)
  	go func() {
  		defer zkManger.Close()
  		for {
  			select {
  			case changeErr:= <-chanErr:
  				fmt.Println("changeErr", changeErr)
  			case changedList := <-chanList:
  				fmt.Println("watch node changed")
  				s.UpdateConf(changedList)
  			}
  		}
  	}()
  }
  
  // UpdateConf 更新配置时，通知监听者也更新
  func (s *LoadBalanceZkConf) UpdateConf(conf []string) {
  	s.activeList = conf
  	for _, obs := range s.observers {
  		obs.Update()
  	}
  }
  
  func NewLoadBalanceZkConf(format, path string, zkHosts []string, conf map[string]string) (*LoadBalanceZkConf, error) {
  	zkManager := compose.NewZkManager(zkHosts)
  	zkManager.BuildConnect()
  	defer zkManager.Close()
  	zlist, err := zkManager.GetServerListByPath(path)
  	if err != nil {
  		return nil, err
  	}
  	mConf := &LoadBalanceZkConf{format: format, activeList: zlist, confIpWeight: conf, zkHosts: zkHosts, path: path}
  	mConf.WatchConf()
  	return mConf, nil
  }
  
  type LoadBalanceObserver struct {
  	ModuleConf *LoadBalanceZkConf
  }
  
  func (l *LoadBalanceObserver) Update() {
  	fmt.Println("Update get conf:", l.ModuleConf.GetConf())
  }
  
  func NewLoadBalanceObserver(conf *LoadBalanceZkConf) *LoadBalanceObserver {
  	return &LoadBalanceObserver{
  		ModuleConf: conf,
  	}
  }
  
  
  
  ```

  